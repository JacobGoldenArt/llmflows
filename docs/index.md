# LLMFlows - Simple, Explicit, and Transparent LLM Apps
<p align="center">
  <img src="llmflows_last_logo.png" />
</p>

[:fontawesome-brands-twitter: Twitter](LLMs.md){ .md-button } [:fontawesome-brands-mastodon: Mastodon](LLMs.md){ .md-button } [:simple-substack: Substack](LLMs.md){ .md-button } [:fontawesome-brands-github: Github](LLMs.md){ .md-button }
***
## About
LLMFlows is a simple and lightweight framework for building LLM-powered applications.

## Installation
```
pip install llmflows
```

## Where to start

After installing `llmflows` with `pip` your go-to destination should be the user guide on the left. Each page helps new users 
gradually learn LLMFlow starting from simple concepts, going through all main abstractions and ending at complex use-cases
where LLMFlow really shines. 

Each page has a TL;DR code snippet that you can just copy, paste and move on. If you already have significant experience with 
LLMs, and prompt engineering or you are in a rush feel free to use the TL;DR section together with the API referrence when needed.

If you are new to LLMs and prompt engineering feel free to go through the user guide in the specified order where you can learn
about concepts, abstractions and patterns when creating LLM-powered applications. 

We hope you find this documentation useful and look forward to any feedback you have on how we can improve it.


## Philosophy

### Simple
Our goal is to build a simple, well documented framework with a minimal set of classes and abstractions that allow users to build flexible LLM-powered apps without compromising on capabilities.

### Explicit
We want to create an explicit API enabling users to write clean, and readable code while being able to easily create complex flows of LLMs interacting with each other.

### Transparent
We aim helping users have full transparency on their LLM-powered apps by providing traceable flows, and complete information for each component of the app making it easy to monitor, maintain, and debug.

## Usage
Here is a minimal example of an LLM with a PromptTemplate:

```python

from llmflows.llms.openai import OpenAI
from llmflows.prompts.prompt_template import PromptTemplate

prompt_template = PromptTemplate(
   prompt="Generate a title for a 90s hip-hop song about {topic}."
)
llm_prompt = prompt_template.get_prompt(topic="friendship")

llm = OpenAI()
song_title = llm.generate(llm_prompt)

```

For more examples such as how to create question answering apps and web applications with Flask and FastAPI check our user guide.

## License
LLMFlows is covered by the MIT license. For more information check `LICENCE.md`.

## Contributing
Thank you for spending the time to read our README! If you like what you saw and are considering contributing please check CONTRIBUTING.md

## Links
Twitter

Github